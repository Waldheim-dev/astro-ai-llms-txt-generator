# ğŸš€ astro-ai-llms-txt

âœ¨ Astro Integration: llms.txt Generator âœ¨

This plugin magically creates a KI-optimized `llms.txt` in your build output on every Astro build!  
Perfect for SEO, AI crawlers, and anyone who loves content. ğŸ¦¾ğŸ“ˆ

## ğŸŒŸ Features

- ğŸ·ï¸ Extracts title, description, H1, H2, H3, and all `<p>` texts from HTML
- ğŸ¤– AI-powered summarization via Ollama, OpenAI, or Gemini (provider/model/key/endpoint configurable)
- ğŸ—„ï¸ AI response caching (SHA256, `.llms-txt-cache` in `dist`)
- ğŸ—‚ï¸ Groups entries by root web section (e.g. `/blog/`, `/services/`)
- ğŸ›¡ï¸ Robust path normalization (OS-independent)
- ğŸª² Debug logging, error detection, build abort on errors

## âš¡ Installation

```bash
npm install astro-ai-llms-txt
```

## ğŸ‰ Usage

Add the plugin to your `astro.config.mjs` and let the magic begin:

```js
import llmsTxt from 'astro-ai-llms-txt';

export default {
  integrations: [
    llmsTxt({
      projectName: 'ğŸš€ My Project',
      description: 'KI-optimized overview for LLMs. ğŸ§ ',
      aiProvider: 'ollama', // 'openai' | 'gemini' | 'ollama'
      aiApiKey: '', // API key for OpenAI/Gemini
      aiModel: 'llama3', // Model name for provider
      site: 'https://my-domain.com', // Base URL for links
      maxInputLength: 8000, // Optional: max length for AI input
    }),
  ],
};
```

### All Options

| Option           | Type   | Default                           | Description                                          |
| ---------------- | ------ | --------------------------------- | ---------------------------------------------------- |
| `projectName`    | string | 'My Project'                      | Name for the llms.txt header                         |
| `description`    | string | 'KI-optimized overview for LLMs.' | Description for llms.txt header                      |
| `aiProvider`     | string | 'ollama'                          | AI provider: 'ollama', 'openai', or 'gemini'         |
| `aiApiKey`       | string | ''                                | API key for OpenAI or Gemini (not needed for Ollama) |
| `aiModel`        | string | 'llama3'                          | Model name for the selected provider                 |
| `aiUrl`          | string | ''                                | Custom endpoint for Ollama (optional)                |
| `site`           | string | ''                                | Base URL for links in llms.txt                       |
| `maxInputLength` | number | 8000                              | Maximum input length for AI summarization            |

## ğŸ“¦ Output

After every Astro build you'll find in `dist/`:

- `llms.txt` â€“ Your KI-optimized overview of all pages âœ¨
- `.llms-txt-cache/` â€“ Cache for AI responses ğŸ—„ï¸

## ğŸ› ï¸ Extending

- Want more AI providers? Just add them in `src/aiProvider.ts`! ğŸ§©
- Tests & coverage: `npm test` âœ…
- Linting: `npm run lint` ğŸ§¹

## ğŸ“ Example llms.txt

```
# ğŸš€ My Project

> KI-optimized overview for LLMs. ğŸ§ 

## Blog

- [/blog/post-1]: Post title summary...
- [/blog/post-2]: Post title summary...

## Services

- [/services/web]: Web service summary...
```

---

Made with â¤ï¸ for Astro & AI enthusiasts!
